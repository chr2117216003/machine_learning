{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "path=\"data/\"\n",
    "inputname=\"human.fasta\"\n",
    "outputname=\"human_PSDSP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.880530973451\n",
      "ACC_all: 0.880530973451\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.853982300885\n",
      "ACC_all: 1.73451327434\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.893805309735\n",
      "ACC_all: 2.62831858407\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.898230088496\n",
      "ACC_all: 3.52654867257\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.898230088496\n",
      "ACC_all: 4.42477876106\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.920353982301\n",
      "ACC_all: 5.34513274336\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.91592920354\n",
      "ACC_all: 6.2610619469\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.933628318584\n",
      "ACC_all: 7.19469026549\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.91592920354\n",
      "ACC_all: 8.11061946903\n",
      "42\n",
      "(2034, 40)\n",
      "(2034, 38)\n",
      "(226, 38)\n",
      "c: 32.0 gamma: 4.0\n",
      "0.946902654867\n",
      "ACC_all: 9.05752212389\n",
      "[[['svmC:32.0gamma:4.0', 0.90575221238938042, 1.0, 0.8115044247787611, 0.8115044247787611, 1.0, 0.9003867257973779, 0.89506461311578389, 0.89506461311578389, 0.82701899297752379, 0.91800610854413034, 917.0, 213.0, 0.0, 1130.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation svm\n",
    "'''\n",
    "classifier=\"SVM\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=0\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "    print len(positive_seq[0])\n",
    "    print np.array(final_seq_value).shape\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "    print np.array(y_final_seq_value).shape\n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    svc = svm.SVC(probability=True)\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "#     parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-5,15,30)), 'gamma':map(lambda x:2**x,np.linspace(-15,5,30))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    C=clf.best_params_['C']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    \n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print 'c:',C,'gamma:',gamma\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[['svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(\"svm_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.880530973451\n",
      "ACC_all: 0.880530973451\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.849557522124\n",
      "ACC_all: 1.73008849558\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.862831858407\n",
      "ACC_all: 2.59292035398\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.893805309735\n",
      "ACC_all: 3.48672566372\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.898230088496\n",
      "ACC_all: 4.38495575221\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.920353982301\n",
      "ACC_all: 5.30530973451\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.898230088496\n",
      "ACC_all: 6.20353982301\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.929203539823\n",
      "ACC_all: 7.13274336283\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.902654867257\n",
      "ACC_all: 8.03539823009\n",
      "(2034, 37)\n",
      "(226, 37)\n",
      "0.946902654867\n",
      "ACC_all: 8.98230088496\n",
      "[[['GBDTn_estimators:111max_depth:3min_samples_split:700min_samples_leaf:90', 0.89823008849557517, 0.982511780901253, 0.8115044247787611, 0.8115044247787611, 0.9849557522123893, 0.8935120174117195, 0.88779431482650017, 0.88779431482650017, 0.80974167474378755, 0.9158101652439502, 917.0, 213.0, 17.0, 1113.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation GBDT\n",
    "'''\n",
    "classifier=\"GBDT\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "    print np.array(y_final_seq_value).shape\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    GBDT = GradientBoostingClassifier(learning_rate=0.1,min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "    parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "    clf = GridSearchCV(GBDT, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    min_samples_split=clf.best_params_['min_samples_split']\n",
    "    min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf)\n",
    "            ,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.849557522124\n",
      "ACC_all: 0.849557522124\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.840707964602\n",
      "ACC_all: 1.69026548673\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.681415929204\n",
      "ACC_all: 2.37168141593\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.880530973451\n",
      "ACC_all: 3.25221238938\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.893805309735\n",
      "ACC_all: 4.14601769912\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.907079646018\n",
      "ACC_all: 5.05309734513\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.907079646018\n",
      "ACC_all: 5.96017699115\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.911504424779\n",
      "ACC_all: 6.87168141593\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.907079646018\n",
      "ACC_all: 7.77876106195\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.933628318584\n",
      "ACC_all: 8.71238938053\n",
      "[[['RFn_estimators:32max_depth:3min_samples_split:700min_samples_leaf:60', 0.8712389380530976, 0.9955555555555555, 0.7442477876106195, 0.7442477876106195, 0.9982300884955752, 0.8578249433399397, 0.84477620075717041, 0.84477620075717041, 0.76930086277738707, 0.90286083483436441, 841.0, 289.0, 2.0, 1128.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation RF\n",
    "'''\n",
    "classifier=\"RF\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    print np.array(final_seq_value).shape\n",
    "    print len(positive_seq[0])\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    RF = RandomForestClassifier(min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "    parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "    clf = GridSearchCV(RF, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    min_samples_split=clf.best_params_['min_samples_split']\n",
    "    min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf)\n",
    "            ,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.880530973451\n",
      "ACC_all: 0.880530973451\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.858407079646\n",
      "ACC_all: 1.7389380531\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.862831858407\n",
      "ACC_all: 2.6017699115\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.871681415929\n",
      "ACC_all: 3.47345132743\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.898230088496\n",
      "ACC_all: 4.37168141593\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.907079646018\n",
      "ACC_all: 5.27876106195\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.907079646018\n",
      "ACC_all: 6.18584070796\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.911504424779\n",
      "ACC_all: 7.09734513274\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.893805309735\n",
      "ACC_all: 7.99115044248\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.951327433628\n",
      "ACC_all: 8.94247787611\n",
      "[[['NB', 0.89424778761061963, 0.9730233975033313, 0.8115044247787611, 0.8115044247787611, 0.976991150442478, 0.8899705403223754, 0.88405486929839106, 0.88405486929839106, 0.80041860023150557, 0.91159135406061553, 917.0, 213.0, 26.0, 1104.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation NB\n",
    "'''\n",
    "classifier=\"NB\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    print np.array(final_seq_value).shape\n",
    "    print len(positive_seq[0])\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    NB=GaussianNB()\n",
    "    NB.fit(X_train,Y_train)\n",
    "    y_pred=NB.predict(X_test)\n",
    "    y_pred_prob=NB.predict_proba(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.884955752212\n",
      "ACC_all: 0.884955752212\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.818584070796\n",
      "ACC_all: 1.70353982301\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.889380530973\n",
      "ACC_all: 2.59292035398\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.836283185841\n",
      "ACC_all: 3.42920353982\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.889380530973\n",
      "ACC_all: 4.3185840708\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.898230088496\n",
      "ACC_all: 5.21681415929\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.884955752212\n",
      "ACC_all: 6.1017699115\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.87610619469\n",
      "ACC_all: 6.97787610619\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.867256637168\n",
      "ACC_all: 7.84513274336\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.924778761062\n",
      "ACC_all: 8.76991150442\n",
      "[[['LRC:10.0', 0.876991150442478, 0.9650902325060648, 0.7831858407079645, 0.7831858407079645, 0.9707964601769911, 0.871481025160769, 0.86373119972088741, 0.86373119972088741, 0.76860314024688126, 0.90017385856370891, 885.0, 245.0, 33.0, 1097.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation LR\n",
    "'''\n",
    "classifier=\"LR\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    print np.array(final_seq_value).shape\n",
    "    print len(positive_seq[0])\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    logisReg = LogisticRegression()\n",
    "    C_range = 10.0 ** np.arange(-4,3,1)\n",
    "    grid_parame = dict(C=C_range)\n",
    "    clf = GridSearchCV(logisReg, grid_parame, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    C=clf.best_params_['C']\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"C:\"+str(C),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.880530973451\n",
      "ACC_all: 0.880530973451\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.840707964602\n",
      "ACC_all: 1.72123893805\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.87610619469\n",
      "ACC_all: 2.59734513274\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.871681415929\n",
      "ACC_all: 3.46902654867\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.893805309735\n",
      "ACC_all: 4.36283185841\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.91592920354\n",
      "ACC_all: 5.27876106195\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.87610619469\n",
      "ACC_all: 6.15486725664\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.902654867257\n",
      "ACC_all: 7.05752212389\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.87610619469\n",
      "ACC_all: 7.93362831858\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.924778761062\n",
      "ACC_all: 8.85840707965\n",
      "[[['KNNn_neighbors:8weights:distancealgorithm:autoleaf_size:1', 0.88584070796460179, 0.9768826681359382, 0.7911504424778762, 0.7911504424778762, 0.9805309734513272, 0.8801636459899893, 0.87305128653428599, 0.87305128653428599, 0.78708691245388385, 0.90349518364789727, 894.0, 236.0, 22.0, 1108.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation KNN\n",
    "'''\n",
    "classifier=\"KNN\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    print np.array(final_seq_value).shape\n",
    "    print len(positive_seq[0])\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    knn = KNeighborsClassifier()\n",
    "    #k\n",
    "    k_range = list(range(1,10))\n",
    "    leaf_range = list(range(1,2))\n",
    "    weight_options = ['uniform','distance']\n",
    "    algorithm_options = ['auto','ball_tree','kd_tree','brute']\n",
    "    param_gridknn = dict(n_neighbors = k_range,weights = weight_options,algorithm=algorithm_options,leaf_size=leaf_range)\n",
    "    clf = GridSearchCV(knn, param_gridknn, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_neighbors=clf.best_params_['n_neighbors']\n",
    "    weights=clf.best_params_['weights']\n",
    "    algorithm=clf.best_params_['algorithm']\n",
    "    leaf_size=clf.best_params_['leaf_size']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_neighbors:\"+str(n_neighbors)+\"weights:\"+str(weights)+\"algorithm:\"+str(algorithm)+\"leaf_size:\"+str(leaf_size),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.880530973451\n",
      "ACC_all: 0.880530973451\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.862831858407\n",
      "ACC_all: 1.74336283186\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.898230088496\n",
      "ACC_all: 2.64159292035\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.893805309735\n",
      "ACC_all: 3.53539823009\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.898230088496\n",
      "ACC_all: 4.43362831858\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.920353982301\n",
      "ACC_all: 5.35398230088\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.920353982301\n",
      "ACC_all: 6.27433628319\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.933628318584\n",
      "ACC_all: 7.20796460177\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.91592920354\n",
      "ACC_all: 8.12389380531\n",
      "(2034, 39)\n",
      "42\n",
      "(2034, 37)\n",
      "0.946902654867\n",
      "ACC_all: 9.07079646018\n",
      "[[['XGBoostn_estimators:9max_depth:9learning_rate:0.1subsample:0.85', 0.90707964601769908, 0.9957876066954883, 0.8176991150442477, 0.8176991150442477, 0.9964601769911503, 0.9022549168096896, 0.89718605846846322, 0.89718605846846322, 0.82818918063798463, 0.9057588691361893, 924.0, 206.0, 4.0, 1126.0, 1130.0, 1130.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cross validation XGBoost\n",
    "'''\n",
    "classifier=\"XGBoost\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "    print np.array(final_seq_value).shape\n",
    "    print len(positive_seq[0])\n",
    "    final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in final_seq_value]\n",
    "    print np.array(final_seq_value).shape\n",
    "\n",
    "    y_final_seq_value=[e[0:((len(positive_seq[0])-1)/2-1)]+e[((len(positive_seq[0])-1)/2+1):] for e in y_final_seq_value]\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    parameters = [{'n_estimators':range(1,10,1),\n",
    "                      'max_depth':range(2,10),\n",
    "                      'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "                      'subsample':[0.75,0.8,0.85,0.9]\n",
    "                      }]\n",
    "    clf = GridSearchCV(XGBClassifier(), parameters, cv=10, n_jobs=1, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    learning_rate=clf.best_params_['learning_rate']\n",
    "    subsample=clf.best_params_['subsample']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"learning_rate:\"+str(learning_rate)+\"subsample:\"+str(subsample),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
